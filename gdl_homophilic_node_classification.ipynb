{"cells":[{"cell_type":"markdown","source":["## imports"],"metadata":{"id":"Ro6db1DfKKNT"},"id":"Ro6db1DfKKNT"},{"cell_type":"code","execution_count":null,"id":"6dc78fe7","metadata":{"id":"6dc78fe7","outputId":"cc141553-7a89-4f13-8948-41118fc98762"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch_geometric in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (2.3.1)\n","Requirement already satisfied: numpy in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from torch_geometric) (1.21.6)\n","Requirement already satisfied: tqdm in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from torch_geometric) (4.66.2)\n","Requirement already satisfied: requests in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: psutil>=5.8.0 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from torch_geometric) (5.9.8)\n","Requirement already satisfied: scipy in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from torch_geometric) (1.7.3)\n","Requirement already satisfied: scikit-learn in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from torch_geometric) (1.0.2)\n","Requirement already satisfied: jinja2 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from torch_geometric) (3.1.3)\n","Requirement already satisfied: pyparsing in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from torch_geometric) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from requests->torch_geometric) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from scikit-learn->torch_geometric) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (from scikit-learn->torch_geometric) (1.3.2)\n"]}],"source":["!pip install torch_geometric"]},{"cell_type":"code","execution_count":null,"id":"89e29c34","metadata":{"id":"89e29c34","outputId":"7531cb6c-3405-4f53-e727-9d283f3bcd47"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: networkx in /homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages (2.6.3)\r\n"]}],"source":["!pip install networkx"]},{"cell_type":"code","execution_count":null,"id":"1d1bd6c8","metadata":{"id":"1d1bd6c8"},"outputs":[],"source":["from torch_geometric.datasets import MNISTSuperpixels, CitationFull\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"id":"274ee09b","metadata":{"id":"274ee09b"},"outputs":[],"source":["import os\n","import torch\n","from torch_geometric.datasets import MNISTSuperpixels\n","from torch_geometric.utils import to_scipy_sparse_matrix\n","import scipy.sparse as sp\n","from scipy.sparse.csgraph import laplacian\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MNISTSuperpixels, CitationFull, WebKB, Actor, WikipediaNetwork\n"]},{"cell_type":"code","execution_count":null,"id":"9554a200","metadata":{"id":"9554a200"},"outputs":[],"source":["if not os.path.exists('dataset/'):\n","    os.makedirs('dataset/')"]},{"cell_type":"markdown","source":["# utils"],"metadata":{"id":"-TSIYpZpKPRn"},"id":"-TSIYpZpKPRn"},{"cell_type":"code","execution_count":null,"id":"0c155049","metadata":{"id":"0c155049"},"outputs":[],"source":["# Function to compute the Laplacian matrix of a graph from PyTorch Geometric\n","def compute_laplacian_pyg(data, normalized=True):\n","    \"\"\"\n","    Compute the Laplacian matrix for a PyTorch Geometric Data object.\n","    \"\"\"\n","    edge_index = data.edge_index\n","    num_nodes = data.num_nodes\n","\n","    # Convert edge_index to a SciPy sparse matrix\n","    adj_matrix = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes)\n","\n","    # Compute the Laplacian\n","    L = laplacian(adj_matrix, normed=normalized)\n","\n","    return L\n","\n","def laplacian_spectrum(L):\n","    eigenvals, eigenvecs = np.linalg.eigh(L)\n","    idx = eigenvals.argsort()\n","    eigenvals = eigenvals[idx]\n","    eigenvecs = eigenvecs[:,idx]\n","    def transform(x, i=0, k=None):\n","        if k is None:\n","            k = len(x)\n","        return eigenvecs[:,i:i+k].T.dot(x)\n","    return transform, eigenvals\n","\n","def laplacian_spectrum_full(L):\n","    eigenvals, eigenvecs = np.linalg.eigh(L)\n","    idx = eigenvals.argsort()\n","    eigenvals = eigenvals[idx]\n","    eigenvecs = eigenvecs[:,idx]\n","    def transform(x, i=0, k=None):\n","        if k is None:\n","            k = len(x)\n","        return eigenvecs[:,i:i+k].T.dot(x)\n","    def inv_transform(xh, i=0, k=None):\n","        if k is None:\n","            k = len(xh)\n","        return eigenvecs[:,i:i+k].dot(xh)\n","    return transform, inv_transform, eigenvals\n","\n","def compute_frequency(dataset_instance, dataset_name):\n","    \"\"\"used to plot the frequency distribution of the node classification datasets\"\"\"\n","    L = compute_laplacian_pyg(dataset_instance, normalized=True)\n","    L_array = L.toarray()\n","    print(\"computing transorm and eigenvalues...\")\n","    transform, eigenvals = laplacian_spectrum(L_array)\n","\n","    x = dataset_instance.x.numpy()\n","\n","    x_transformed = transform(x)\n","\n","    dataset_x_sum = np.sum(np.abs(x_transformed), axis=1)\n","\n","\n","    plt.figure(figsize=(7, 5))\n","    plt.stem(eigenvals, dataset_x_sum, use_line_collection=True)\n","    plt.title('Summed Distribution of Frequency Components Across All Features in '+ dataset_name)\n","    plt.xlim([-0.05, 2])\n","    plt.xlabel('Eigenvalue (Frequency)')\n","    plt.ylabel('Summed Magnitude')\n","    plt.grid(True)\n","    plt.show()\n","    filename = dataset_name.replace(\" \", \"_\") + '_Frequency_Distribution.png'\n","    # plt.savefig(filename,dpi=600)  # Save the plot as a PNG file\n","    print(f'Plot saved as {filename}')\n","    plt.close()\n","\n","\n","def plot_graphs_from_dataset(dataset, num_examples=3):\n","    \"\"\"use to plot some examples from graph classification datasets\"\"\"\n","    plt.figure(figsize=(15, 5))\n","\n","    for i in range(min(num_examples, len(dataset))):\n","        graph = dataset[i]\n","        nx_graph = to_networkx(graph, to_undirected=True)\n","\n","        plt.subplot(1, num_examples, i+1)\n","        nx.draw(nx_graph, with_labels=True, node_color='skyblue', edge_color='k', node_size=700, font_size=10)\n","        plt.title(f'Graph {i+1}')\n","\n","    plt.show()\n"]},{"cell_type":"markdown","source":["# semi-supervised node classification on Homophilic graphs"],"metadata":{"id":"TnlRJh84MSOj"},"id":"TnlRJh84MSOj"},{"cell_type":"markdown","source":["## Datasets"],"metadata":{"id":"-ryusrjMMIoY"},"id":"-ryusrjMMIoY"},{"cell_type":"code","execution_count":null,"id":"27b1eda3","metadata":{"id":"27b1eda3"},"outputs":[],"source":["# dataset_mnist = MNISTSuperpixels(root='dataset/MNIST/', train=True)\n","dataset_cora = CitationFull(root='dataset/Cora/', name = \"Cora\")\n","dataset_citeseer = CitationFull(root='dataset/CiteSeer/', name = \"CiteSeer\")\n","dataset_pubmed = CitationFull(root='dataset/PubMed/', name = \"PubMed\")"]},{"cell_type":"code","execution_count":null,"id":"f46b2868","metadata":{"id":"f46b2868","outputId":"2677370c-6229-464a-d51e-f795f641b32b"},"outputs":[{"name":"stdout","output_type":"stream","text":["computing transorm and eigenvalues...\n","Plot saved as Cora_Frequency_Distribution.png\n"]}],"source":["compute_frequency(dataset_cora[0], 'Cora')"]},{"cell_type":"code","execution_count":null,"id":"95a423db","metadata":{"id":"95a423db","outputId":"0c66ba42-a882-42a2-c3b4-96bfba00452b"},"outputs":[{"name":"stdout","output_type":"stream","text":["computing transorm and eigenvalues...\n","Plot saved as Citeseer_Frequency_Distribution.png\n"]}],"source":["compute_frequency(dataset_citeseer[0], 'Citeseer')"]},{"cell_type":"code","execution_count":null,"id":"26ac2b64","metadata":{"id":"26ac2b64","outputId":"ffe4b8a8-b5b6-48e2-d31e-050078caae84"},"outputs":[{"name":"stdout","output_type":"stream","text":["computing transorm and eigenvalues...\n","Plot saved as Pubmed_Frequency_Distribution.png\n"]}],"source":["compute_frequency(dataset_pubmed[0], 'Pubmed')"]},{"cell_type":"code","source":[],"metadata":{"id":"X2-xlto3Yq6C"},"id":"X2-xlto3Yq6C","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define GCN and ChebNet"],"metadata":{"id":"P8Nm_djhYvrM"},"id":"P8Nm_djhYvrM"},{"cell_type":"code","execution_count":null,"id":"23dd2047","metadata":{"id":"23dd2047"},"outputs":[],"source":["\n","import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","class GCNModel_semi(torch.nn.Module):\n","    def __init__(self, num_features, num_classes):\n","        super(GCNModel_semi, self).__init__()\n","        self.conv1 = GCNConv(num_features, 16)\n","        self.conv2 = GCNConv(16, num_classes)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n","\n","from torch_geometric.nn import ChebConv\n","\n","class ChebNetModel_semi(torch.nn.Module):\n","    def __init__(self, num_features, num_classes, K=3):\n","        super(ChebNetModel_semi, self).__init__()\n","        self.cheb1 = ChebConv(num_features, 16, K)\n","        self.cheb2 = ChebConv(16, num_classes, K)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = F.relu(self.cheb1(x, edge_index))\n","        x = F.dropout(x, training=self.training)\n","        x = self.cheb2(x, edge_index)\n","        return F.log_softmax(x, dim=1)\n"]},{"cell_type":"code","execution_count":null,"id":"e0277651","metadata":{"id":"e0277651"},"outputs":[],"source":["def train(model, optimizer, data, criterion, device='cuda'):\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data)\n","    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()\n","\n","def test(model, data, device='cuda'):\n","    model.eval()\n","    logits, accs = model(data), []\n","    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n","        pred = logits[mask].max(1)[1]\n","        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n","        accs.append(acc)\n","    return accs\n"]},{"cell_type":"code","execution_count":null,"id":"17fee197","metadata":{"id":"17fee197"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","\n","import torch\n","\n","def add_train_test_masks_to_dataset(dataset):\n","    num_nodes = dataset.data.num_nodes\n","    num_train = int(0.8 * num_nodes)\n","    num_test = num_nodes - num_train\n","\n","    # Create masks\n","    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","\n","    # Randomly select indices for train/test\n","    indices = torch.randperm(num_nodes)\n","    train_indices, test_indices = indices[:num_train], indices[num_train:]\n","\n","    train_mask[train_indices] = True\n","    test_mask[test_indices] = True\n","\n","    # Add masks to the dataset\n","    dataset.data.train_mask = train_mask\n","    dataset.data.test_mask = test_mask\n","\n","    return dataset\n","\n","\n","def data_load_sep_for_node_classification(dataset):\n","    \"\"\"get feasures of dataset\"\"\"\n","    data = dataset.data\n","\n","    if hasattr(data, 'train_mask') and hasattr(data, 'test_mask'):\n","        train_mask = data.train_mask\n","        test_mask = data.test_mask\n","    else:\n","        raise AttributeError(\"Dataset does not have 'train_mask' and 'test_mask' attributes.\")\n","\n","    # DataLoader setup\n","    loader = DataLoader(dataset, batch_size=1, shuffle=False)  # Single batch for the whole graph\n","\n","    num_features = dataset.num_features\n","    num_classes = dataset.num_classes\n","\n","    # Return the loader and masks\n","    return num_features, num_classes, loader, train_mask, test_mask"]},{"cell_type":"code","execution_count":null,"id":"18d34ff9","metadata":{"id":"18d34ff9"},"outputs":[],"source":["\n","def run_experiment_semi_supervised(model_class, optimizer_class, dataset, criterion, device=\"cuda\", num_runs=5, epochs=200):\n","    all_losses = []  # To store losses from all runs\n","    accuracies = []\n","    data = dataset[0].to(device)  # Assuming a single-graph dataset\n","\n","    # Masks are assumed to be part of the dataset\n","    train_mask = data.train_mask\n","    test_mask = data.test_mask\n","\n","    for run in range(num_runs):\n","        model = model_class(dataset.num_features, dataset.num_classes).to(device)\n","        optimizer = optimizer_class(model.parameters(), lr=0.01)\n","        run_losses = []  # To store losses for the current run\n","\n","        # Train the model\n","        for epoch in range(epochs):\n","            model.train()\n","            optimizer.zero_grad()\n","            out = model(data)\n","            loss = criterion(out[train_mask], data.y[train_mask])\n","            loss.backward()\n","            optimizer.step()\n","\n","            if epoch % 10 == 0:  # Record loss every 10 epochs\n","                run_losses.append(loss.item())\n","                print(f'Run {run + 1}, Epoch {epoch}: Loss {loss.item():.4f}')\n","\n","        all_losses.append(run_losses)  # Store the losses for this run\n","\n","        # Test the model\n","        model.eval()\n","        _, pred = model(data).max(dim=1)\n","        correct = float(pred[test_mask].eq(data.y[test_mask]).sum().item())\n","        acc = correct / test_mask.sum().item()\n","        accuracies.append(acc)\n","\n","        print(f'Run {run + 1}: Model Test Accuracy: {acc:.4f}')\n","\n","    avg_accuracy = sum(accuracies) / num_runs\n","    print(f'Average Test Accuracy over {num_runs} runs: {avg_accuracy:.4f}')\n","    return avg_accuracy, all_losses\n","\n","\n","\n","def data_load_sep(dataset):\n","    dataset = dataset.shuffle()\n","\n","    train_size = int(len(dataset) * 0.8)  # 80% for training\n","    test_size = len(dataset) - train_size\n","\n","    train_dataset, test_dataset = dataset[:train_size], dataset[train_size:]\n","\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    num_features = train_dataset.num_features\n","    num_classes = train_dataset.num_classes\n","\n","    return num_features, num_classes,train_loader, test_loader\n"]},{"cell_type":"code","execution_count":null,"id":"758ef221","metadata":{"id":"758ef221"},"outputs":[],"source":["import torch\n","\n","def add_train_val_test_masks_to_dataset(dataset, train_percent=0.7, val_percent=0.1):\n","    \"\"\"\n","    Add train, validation, and test masks to the dataset for semi-supervised learning.\n","\n","    Parameters:\n","    - dataset: The dataset object, assumed to contain a single graph.\n","    - train_percent: The percentage of nodes used for training.\n","    - val_percent: The percentage of nodes used for validation.\n","    \"\"\"\n","    num_nodes = dataset.data.num_nodes\n","    num_train = int(train_percent * num_nodes)\n","    num_val = int(val_percent * num_nodes)\n","    num_test = num_nodes - num_train - num_val\n","\n","    # Initialize masks\n","    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","\n","    # Ensure labels are evenly distributed across splits\n","    labels = dataset.data.y.cpu().numpy()\n","    unique_labels = torch.unique(dataset.data.y).cpu().numpy()\n","\n","    for label in unique_labels:\n","        label_indices = torch.where(dataset.data.y == label)[0]\n","        # Shuffle indices of the current label\n","        label_indices = label_indices[torch.randperm(len(label_indices))]\n","\n","        # Calculate split sizes for the current label\n","        num_label_train = int(train_percent * len(label_indices))\n","        num_label_val = int(val_percent * len(label_indices))\n","\n","        # Assign splits for the current label\n","        train_mask[label_indices[:num_label_train]] = True\n","        val_mask[label_indices[num_label_train:num_label_train + num_label_val]] = True\n","        test_mask[label_indices[num_label_train + num_label_val:]] = True\n","\n","    # Add masks to the dataset\n","    dataset.data.train_mask = train_mask\n","    dataset.data.val_mask = val_mask\n","    dataset.data.test_mask = test_mask\n","\n","    return dataset\n"]},{"cell_type":"code","execution_count":null,"id":"1689ae0b","metadata":{"id":"1689ae0b"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","\n","def data_load_sep_for_semi_supervised(dataset):\n","    \"\"\"\n","    data loaders and masks for semi-supervised node classification task.\n","    \"\"\"\n","    data = dataset.data\n","\n","    # Check for required masks\n","    required_masks = ['train_mask', 'val_mask', 'test_mask']\n","    for mask_name in required_masks:\n","        if not hasattr(data, mask_name):\n","            raise AttributeError(f\"Dataset does not have '{mask_name}'. Please add it before calling this function.\")\n","    train_mask = data.train_mask\n","    val_mask = data.val_mask\n","    test_mask = data.test_mask\n","\n","    loader = DataLoader(dataset, batch_size=1, shuffle=False)  # Process the whole graph at once\n","\n","    num_features = dataset.num_features\n","    num_classes = dataset.num_classes\n","\n","    return num_features, num_classes, loader, train_mask, val_mask, test_mask\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","criterion = torch.nn.CrossEntropyLoss()\n"]},{"cell_type":"code","execution_count":null,"id":"6a259496","metadata":{"id":"6a259496"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_losses(losses1, losses2, label1='Run 1 Loss', label2='Run 2 Loss'):\n","    \"\"\"\n","    Plots the training losses from two experimental runs.\n","\n","    Parameters:\n","    - losses1: List of losses from the first run.\n","    - losses2: List of losses from the second run.\n","    - label1: Label for the first run.\n","    - label2: Label for the second run.\n","    \"\"\"\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(losses1, label=label1, marker='o')\n","    plt.plot(losses2, label=label2, marker='x')\n","    plt.title('Training Losses Comparison')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n"]},{"cell_type":"markdown","source":["# Cora"],"metadata":{"id":"1jjLH_d1Y4CS"},"id":"1jjLH_d1Y4CS"},{"cell_type":"code","execution_count":null,"id":"0a36fdba","metadata":{"id":"0a36fdba"},"outputs":[],"source":["dataset_cora2 = add_train_val_test_masks_to_dataset(dataset_cora)"]},{"cell_type":"markdown","id":"f7b4e89e","metadata":{"id":"f7b4e89e"},"source":["## GCN"]},{"cell_type":"code","execution_count":null,"id":"fbfccb1c","metadata":{"id":"fbfccb1c","outputId":"d0c557e1-b8cd-47fb-f568-3bdf6e686461"},"outputs":[{"name":"stdout","output_type":"stream","text":["Run 1, Epoch 0: Loss 1.0660\n","Run 1, Epoch 10: Loss 0.5257\n","Run 1, Epoch 20: Loss 0.4254\n","Run 1, Epoch 30: Loss 0.3875\n","Run 1, Epoch 40: Loss 0.3563\n","Run 1, Epoch 50: Loss 0.3418\n","Run 1, Epoch 60: Loss 0.3251\n","Run 1, Epoch 70: Loss 0.3126\n","Run 1, Epoch 80: Loss 0.2988\n","Run 1, Epoch 90: Loss 0.2941\n","Run 1, Epoch 100: Loss 0.2819\n","Run 1, Epoch 110: Loss 0.2784\n","Run 1, Epoch 120: Loss 0.2717\n","Run 1, Epoch 130: Loss 0.2658\n","Run 1, Epoch 140: Loss 0.2632\n","Run 1, Epoch 150: Loss 0.2545\n","Run 1, Epoch 160: Loss 0.2492\n","Run 1, Epoch 170: Loss 0.2467\n","Run 1, Epoch 180: Loss 0.2397\n","Run 1, Epoch 190: Loss 0.2363\n","Run 1: Model Test Accuracy: 0.8786\n","Run 2, Epoch 0: Loss 1.1047\n","Run 2, Epoch 10: Loss 0.5239\n","Run 2, Epoch 20: Loss 0.4380\n","Run 2, Epoch 30: Loss 0.4032\n","Run 2, Epoch 40: Loss 0.3695\n","Run 2, Epoch 50: Loss 0.3522\n","Run 2, Epoch 60: Loss 0.3390\n","Run 2, Epoch 70: Loss 0.3224\n","Run 2, Epoch 80: Loss 0.3140\n","Run 2, Epoch 90: Loss 0.3076\n","Run 2, Epoch 100: Loss 0.2971\n","Run 2, Epoch 110: Loss 0.2939\n","Run 2, Epoch 120: Loss 0.2835\n","Run 2, Epoch 130: Loss 0.2810\n","Run 2, Epoch 140: Loss 0.2764\n","Run 2, Epoch 150: Loss 0.2719\n","Run 2, Epoch 160: Loss 0.2683\n","Run 2, Epoch 170: Loss 0.2554\n","Run 2, Epoch 180: Loss 0.2564\n","Run 2, Epoch 190: Loss 0.2577\n","Run 2: Model Test Accuracy: 0.8796\n","Run 3, Epoch 0: Loss 1.0888\n","Run 3, Epoch 10: Loss 0.5129\n","Run 3, Epoch 20: Loss 0.4317\n","Run 3, Epoch 30: Loss 0.3928\n","Run 3, Epoch 40: Loss 0.3631\n","Run 3, Epoch 50: Loss 0.3520\n","Run 3, Epoch 60: Loss 0.3395\n","Run 3, Epoch 70: Loss 0.3252\n","Run 3, Epoch 80: Loss 0.3165\n","Run 3, Epoch 90: Loss 0.3084\n","Run 3, Epoch 100: Loss 0.3002\n","Run 3, Epoch 110: Loss 0.2932\n","Run 3, Epoch 120: Loss 0.2891\n","Run 3, Epoch 130: Loss 0.2824\n","Run 3, Epoch 140: Loss 0.2754\n","Run 3, Epoch 150: Loss 0.2726\n","Run 3, Epoch 160: Loss 0.2737\n","Run 3, Epoch 170: Loss 0.2621\n","Run 3, Epoch 180: Loss 0.2597\n","Run 3, Epoch 190: Loss 0.2546\n","Run 3: Model Test Accuracy: 0.8794\n","Run 4, Epoch 0: Loss 1.1165\n","Run 4, Epoch 10: Loss 0.5261\n","Run 4, Epoch 20: Loss 0.4318\n","Run 4, Epoch 30: Loss 0.3914\n","Run 4, Epoch 40: Loss 0.3683\n","Run 4, Epoch 50: Loss 0.3491\n","Run 4, Epoch 60: Loss 0.3362\n","Run 4, Epoch 70: Loss 0.3215\n","Run 4, Epoch 80: Loss 0.3149\n","Run 4, Epoch 90: Loss 0.3042\n","Run 4, Epoch 100: Loss 0.2959\n","Run 4, Epoch 110: Loss 0.2947\n","Run 4, Epoch 120: Loss 0.2840\n","Run 4, Epoch 130: Loss 0.2818\n","Run 4, Epoch 140: Loss 0.2760\n","Run 4, Epoch 150: Loss 0.2672\n","Run 4, Epoch 160: Loss 0.2715\n","Run 4, Epoch 170: Loss 0.2683\n","Run 4, Epoch 180: Loss 0.2583\n","Run 4, Epoch 190: Loss 0.2563\n","Run 4: Model Test Accuracy: 0.8799\n","Run 5, Epoch 0: Loss 1.1230\n","Run 5, Epoch 10: Loss 0.5359\n","Run 5, Epoch 20: Loss 0.4452\n","Run 5, Epoch 30: Loss 0.3985\n","Run 5, Epoch 40: Loss 0.3794\n","Run 5, Epoch 50: Loss 0.3529\n","Run 5, Epoch 60: Loss 0.3351\n","Run 5, Epoch 70: Loss 0.3233\n","Run 5, Epoch 80: Loss 0.3136\n","Run 5, Epoch 90: Loss 0.3025\n","Run 5, Epoch 100: Loss 0.2995\n","Run 5, Epoch 110: Loss 0.2902\n","Run 5, Epoch 120: Loss 0.2839\n","Run 5, Epoch 130: Loss 0.2798\n","Run 5, Epoch 140: Loss 0.2753\n","Run 5, Epoch 150: Loss 0.2693\n","Run 5, Epoch 160: Loss 0.2636\n","Run 5, Epoch 170: Loss 0.2583\n","Run 5, Epoch 180: Loss 0.2568\n","Run 5, Epoch 190: Loss 0.2552\n","Run 5: Model Test Accuracy: 0.8776\n","Average Test Accuracy over 5 runs: 0.8790\n"]}],"source":["avg_accuracy, loss_cora = run_experiment_semi_supervised(GCNModel_semi, torch.optim.Adam,dataset_cora2, criterion)\n"]},{"cell_type":"markdown","id":"6f6f3842","metadata":{"id":"6f6f3842"},"source":["## GhebNet"]},{"cell_type":"code","execution_count":null,"id":"c5f64f9a","metadata":{"id":"c5f64f9a","outputId":"424f26ba-5b7d-4892-8449-e8c360bef168"},"outputs":[{"name":"stdout","output_type":"stream","text":["Run 1, Epoch 0: Loss 1.5637\n","Run 1, Epoch 10: Loss 0.8667\n","Run 1, Epoch 20: Loss 0.7281\n","Run 1, Epoch 30: Loss 0.5681\n","Run 1, Epoch 40: Loss 0.4478\n","Run 1, Epoch 50: Loss 0.3998\n","Run 1, Epoch 60: Loss 0.3723\n","Run 1, Epoch 70: Loss 0.3483\n","Run 1, Epoch 80: Loss 0.3325\n","Run 1, Epoch 90: Loss 0.3185\n","Run 1, Epoch 100: Loss 0.2954\n","Run 1, Epoch 110: Loss 0.2953\n","Run 1, Epoch 120: Loss 0.2827\n","Run 1, Epoch 130: Loss 0.2745\n","Run 1, Epoch 140: Loss 0.2682\n","Run 1, Epoch 150: Loss 0.2612\n","Run 1, Epoch 160: Loss 0.2485\n","Run 1, Epoch 170: Loss 0.2444\n","Run 1, Epoch 180: Loss 0.2378\n","Run 1, Epoch 190: Loss 0.2361\n","Run 1: Model Test Accuracy: 0.8842\n","Run 2, Epoch 0: Loss 1.5137\n","Run 2, Epoch 10: Loss 0.6887\n","Run 2, Epoch 20: Loss 0.5555\n","Run 2, Epoch 30: Loss 0.4772\n","Run 2, Epoch 40: Loss 0.4271\n","Run 2, Epoch 50: Loss 0.4047\n","Run 2, Epoch 60: Loss 0.3870\n","Run 2, Epoch 70: Loss 0.3682\n","Run 2, Epoch 80: Loss 0.3614\n","Run 2, Epoch 90: Loss 0.3422\n","Run 2, Epoch 100: Loss 0.3316\n","Run 2, Epoch 110: Loss 0.3176\n","Run 2, Epoch 120: Loss 0.3097\n","Run 2, Epoch 130: Loss 0.3036\n","Run 2, Epoch 140: Loss 0.2981\n","Run 2, Epoch 150: Loss 0.2942\n","Run 2, Epoch 160: Loss 0.2883\n","Run 2, Epoch 170: Loss 0.2811\n","Run 2, Epoch 180: Loss 0.2728\n","Run 2, Epoch 190: Loss 0.2704\n","Run 2: Model Test Accuracy: 0.8865\n","Run 3, Epoch 0: Loss 1.9000\n","Run 3, Epoch 10: Loss 0.7492\n","Run 3, Epoch 20: Loss 0.6388\n","Run 3, Epoch 30: Loss 0.5668\n","Run 3, Epoch 40: Loss 0.5277\n","Run 3, Epoch 50: Loss 0.4917\n","Run 3, Epoch 60: Loss 0.4671\n","Run 3, Epoch 70: Loss 0.4461\n","Run 3, Epoch 80: Loss 0.4259\n","Run 3, Epoch 90: Loss 0.4111\n","Run 3, Epoch 100: Loss 0.3918\n","Run 3, Epoch 110: Loss 0.3811\n","Run 3, Epoch 120: Loss 0.3680\n","Run 3, Epoch 130: Loss 0.3534\n","Run 3, Epoch 140: Loss 0.3426\n","Run 3, Epoch 150: Loss 0.3233\n","Run 3, Epoch 160: Loss 0.3050\n","Run 3, Epoch 170: Loss 0.3045\n","Run 3, Epoch 180: Loss 0.2981\n","Run 3, Epoch 190: Loss 0.2942\n","Run 3: Model Test Accuracy: 0.8789\n","Run 4, Epoch 0: Loss 1.5527\n","Run 4, Epoch 10: Loss 0.6999\n","Run 4, Epoch 20: Loss 0.5039\n","Run 4, Epoch 30: Loss 0.4217\n","Run 4, Epoch 40: Loss 0.3683\n","Run 4, Epoch 50: Loss 0.3377\n","Run 4, Epoch 60: Loss 0.3157\n","Run 4, Epoch 70: Loss 0.2930\n","Run 4, Epoch 80: Loss 0.2826\n","Run 4, Epoch 90: Loss 0.2685\n","Run 4, Epoch 100: Loss 0.2565\n","Run 4, Epoch 110: Loss 0.2449\n","Run 4, Epoch 120: Loss 0.2340\n","Run 4, Epoch 130: Loss 0.2307\n","Run 4, Epoch 140: Loss 0.2259\n","Run 4, Epoch 150: Loss 0.2213\n","Run 4, Epoch 160: Loss 0.2135\n","Run 4, Epoch 170: Loss 0.2062\n","Run 4, Epoch 180: Loss 0.1988\n","Run 4, Epoch 190: Loss 0.1905\n","Run 4: Model Test Accuracy: 0.8829\n","Run 5, Epoch 0: Loss 1.6236\n","Run 5, Epoch 10: Loss 0.8790\n","Run 5, Epoch 20: Loss 0.6185\n","Run 5, Epoch 30: Loss 0.4970\n","Run 5, Epoch 40: Loss 0.4431\n","Run 5, Epoch 50: Loss 0.4049\n","Run 5, Epoch 60: Loss 0.3921\n","Run 5, Epoch 70: Loss 0.3673\n","Run 5, Epoch 80: Loss 0.3532\n","Run 5, Epoch 90: Loss 0.3382\n","Run 5, Epoch 100: Loss 0.3300\n","Run 5, Epoch 110: Loss 0.3246\n","Run 5, Epoch 120: Loss 0.3088\n","Run 5, Epoch 130: Loss 0.3057\n","Run 5, Epoch 140: Loss 0.2968\n","Run 5, Epoch 150: Loss 0.2965\n","Run 5, Epoch 160: Loss 0.2862\n","Run 5, Epoch 170: Loss 0.2748\n","Run 5, Epoch 180: Loss 0.2660\n","Run 5, Epoch 190: Loss 0.2619\n","Run 5: Model Test Accuracy: 0.8781\n","Average Test Accuracy over 5 runs: 0.8821\n"]}],"source":["avg_accuracy_cheb_cora, loss_cora_cheb = run_experiment_semi_supervised(ChebNetModel_semi, torch.optim.Adam,dataset_cora2, criterion)\n"]},{"cell_type":"code","execution_count":null,"id":"7e60bfe6","metadata":{"id":"7e60bfe6"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Citeseer"],"metadata":{"id":"Ua5mlI9CZEBA"},"id":"Ua5mlI9CZEBA"},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5tRTAd0ZEBA"},"outputs":[],"source":["dataset_citeseer2 = add_train_val_test_masks_to_dataset(dataset_citeseer)"],"id":"o5tRTAd0ZEBA"},{"cell_type":"markdown","metadata":{"id":"l0FT4x95ZEBB"},"source":["## GCN"],"id":"l0FT4x95ZEBB"},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"d0c557e1-b8cd-47fb-f568-3bdf6e686461","id":"u9qMREuYZEBB"},"outputs":[{"name":"stdout","output_type":"stream","text":["Run 1, Epoch 0: Loss 1.0660\n","Run 1, Epoch 10: Loss 0.5257\n","Run 1, Epoch 20: Loss 0.4254\n","Run 1, Epoch 30: Loss 0.3875\n","Run 1, Epoch 40: Loss 0.3563\n","Run 1, Epoch 50: Loss 0.3418\n","Run 1, Epoch 60: Loss 0.3251\n","Run 1, Epoch 70: Loss 0.3126\n","Run 1, Epoch 80: Loss 0.2988\n","Run 1, Epoch 90: Loss 0.2941\n","Run 1, Epoch 100: Loss 0.2819\n","Run 1, Epoch 110: Loss 0.2784\n","Run 1, Epoch 120: Loss 0.2717\n","Run 1, Epoch 130: Loss 0.2658\n","Run 1, Epoch 140: Loss 0.2632\n","Run 1, Epoch 150: Loss 0.2545\n","Run 1, Epoch 160: Loss 0.2492\n","Run 1, Epoch 170: Loss 0.2467\n","Run 1, Epoch 180: Loss 0.2397\n","Run 1, Epoch 190: Loss 0.2363\n","Run 1: Model Test Accuracy: 0.8786\n","Run 2, Epoch 0: Loss 1.1047\n","Run 2, Epoch 10: Loss 0.5239\n","Run 2, Epoch 20: Loss 0.4380\n","Run 2, Epoch 30: Loss 0.4032\n","Run 2, Epoch 40: Loss 0.3695\n","Run 2, Epoch 50: Loss 0.3522\n","Run 2, Epoch 60: Loss 0.3390\n","Run 2, Epoch 70: Loss 0.3224\n","Run 2, Epoch 80: Loss 0.3140\n","Run 2, Epoch 90: Loss 0.3076\n","Run 2, Epoch 100: Loss 0.2971\n","Run 2, Epoch 110: Loss 0.2939\n","Run 2, Epoch 120: Loss 0.2835\n","Run 2, Epoch 130: Loss 0.2810\n","Run 2, Epoch 140: Loss 0.2764\n","Run 2, Epoch 150: Loss 0.2719\n","Run 2, Epoch 160: Loss 0.2683\n","Run 2, Epoch 170: Loss 0.2554\n","Run 2, Epoch 180: Loss 0.2564\n","Run 2, Epoch 190: Loss 0.2577\n","Run 2: Model Test Accuracy: 0.8796\n","Run 3, Epoch 0: Loss 1.0888\n","Run 3, Epoch 10: Loss 0.5129\n","Run 3, Epoch 20: Loss 0.4317\n","Run 3, Epoch 30: Loss 0.3928\n","Run 3, Epoch 40: Loss 0.3631\n","Run 3, Epoch 50: Loss 0.3520\n","Run 3, Epoch 60: Loss 0.3395\n","Run 3, Epoch 70: Loss 0.3252\n","Run 3, Epoch 80: Loss 0.3165\n","Run 3, Epoch 90: Loss 0.3084\n","Run 3, Epoch 100: Loss 0.3002\n","Run 3, Epoch 110: Loss 0.2932\n","Run 3, Epoch 120: Loss 0.2891\n","Run 3, Epoch 130: Loss 0.2824\n","Run 3, Epoch 140: Loss 0.2754\n","Run 3, Epoch 150: Loss 0.2726\n","Run 3, Epoch 160: Loss 0.2737\n","Run 3, Epoch 170: Loss 0.2621\n","Run 3, Epoch 180: Loss 0.2597\n","Run 3, Epoch 190: Loss 0.2546\n","Run 3: Model Test Accuracy: 0.8794\n","Run 4, Epoch 0: Loss 1.1165\n","Run 4, Epoch 10: Loss 0.5261\n","Run 4, Epoch 20: Loss 0.4318\n","Run 4, Epoch 30: Loss 0.3914\n","Run 4, Epoch 40: Loss 0.3683\n","Run 4, Epoch 50: Loss 0.3491\n","Run 4, Epoch 60: Loss 0.3362\n","Run 4, Epoch 70: Loss 0.3215\n","Run 4, Epoch 80: Loss 0.3149\n","Run 4, Epoch 90: Loss 0.3042\n","Run 4, Epoch 100: Loss 0.2959\n","Run 4, Epoch 110: Loss 0.2947\n","Run 4, Epoch 120: Loss 0.2840\n","Run 4, Epoch 130: Loss 0.2818\n","Run 4, Epoch 140: Loss 0.2760\n","Run 4, Epoch 150: Loss 0.2672\n","Run 4, Epoch 160: Loss 0.2715\n","Run 4, Epoch 170: Loss 0.2683\n","Run 4, Epoch 180: Loss 0.2583\n","Run 4, Epoch 190: Loss 0.2563\n","Run 4: Model Test Accuracy: 0.8799\n","Run 5, Epoch 0: Loss 1.1230\n","Run 5, Epoch 10: Loss 0.5359\n","Run 5, Epoch 20: Loss 0.4452\n","Run 5, Epoch 30: Loss 0.3985\n","Run 5, Epoch 40: Loss 0.3794\n","Run 5, Epoch 50: Loss 0.3529\n","Run 5, Epoch 60: Loss 0.3351\n","Run 5, Epoch 70: Loss 0.3233\n","Run 5, Epoch 80: Loss 0.3136\n","Run 5, Epoch 90: Loss 0.3025\n","Run 5, Epoch 100: Loss 0.2995\n","Run 5, Epoch 110: Loss 0.2902\n","Run 5, Epoch 120: Loss 0.2839\n","Run 5, Epoch 130: Loss 0.2798\n","Run 5, Epoch 140: Loss 0.2753\n","Run 5, Epoch 150: Loss 0.2693\n","Run 5, Epoch 160: Loss 0.2636\n","Run 5, Epoch 170: Loss 0.2583\n","Run 5, Epoch 180: Loss 0.2568\n","Run 5, Epoch 190: Loss 0.2552\n","Run 5: Model Test Accuracy: 0.8776\n","Average Test Accuracy over 5 runs: 0.8790\n"]}],"source":["avg_accuracy_gcn_citeseer, loss_citeseer = run_experiment_semi_supervised(GCNModel_semi, torch.optim.Adam,dataset_citeseer2, criterion)\n"],"id":"u9qMREuYZEBB"},{"cell_type":"markdown","metadata":{"id":"4wX-uTrhZEBB"},"source":["## GhebNet"],"id":"4wX-uTrhZEBB"},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"424f26ba-5b7d-4892-8449-e8c360bef168","id":"SLiAA3L1ZEBB"},"outputs":[{"name":"stdout","output_type":"stream","text":["Run 1, Epoch 0: Loss 1.5637\n","Run 1, Epoch 10: Loss 0.8667\n","Run 1, Epoch 20: Loss 0.7281\n","Run 1, Epoch 30: Loss 0.5681\n","Run 1, Epoch 40: Loss 0.4478\n","Run 1, Epoch 50: Loss 0.3998\n","Run 1, Epoch 60: Loss 0.3723\n","Run 1, Epoch 70: Loss 0.3483\n","Run 1, Epoch 80: Loss 0.3325\n","Run 1, Epoch 90: Loss 0.3185\n","Run 1, Epoch 100: Loss 0.2954\n","Run 1, Epoch 110: Loss 0.2953\n","Run 1, Epoch 120: Loss 0.2827\n","Run 1, Epoch 130: Loss 0.2745\n","Run 1, Epoch 140: Loss 0.2682\n","Run 1, Epoch 150: Loss 0.2612\n","Run 1, Epoch 160: Loss 0.2485\n","Run 1, Epoch 170: Loss 0.2444\n","Run 1, Epoch 180: Loss 0.2378\n","Run 1, Epoch 190: Loss 0.2361\n","Run 1: Model Test Accuracy: 0.8842\n","Run 2, Epoch 0: Loss 1.5137\n","Run 2, Epoch 10: Loss 0.6887\n","Run 2, Epoch 20: Loss 0.5555\n","Run 2, Epoch 30: Loss 0.4772\n","Run 2, Epoch 40: Loss 0.4271\n","Run 2, Epoch 50: Loss 0.4047\n","Run 2, Epoch 60: Loss 0.3870\n","Run 2, Epoch 70: Loss 0.3682\n","Run 2, Epoch 80: Loss 0.3614\n","Run 2, Epoch 90: Loss 0.3422\n","Run 2, Epoch 100: Loss 0.3316\n","Run 2, Epoch 110: Loss 0.3176\n","Run 2, Epoch 120: Loss 0.3097\n","Run 2, Epoch 130: Loss 0.3036\n","Run 2, Epoch 140: Loss 0.2981\n","Run 2, Epoch 150: Loss 0.2942\n","Run 2, Epoch 160: Loss 0.2883\n","Run 2, Epoch 170: Loss 0.2811\n","Run 2, Epoch 180: Loss 0.2728\n","Run 2, Epoch 190: Loss 0.2704\n","Run 2: Model Test Accuracy: 0.8865\n","Run 3, Epoch 0: Loss 1.9000\n","Run 3, Epoch 10: Loss 0.7492\n","Run 3, Epoch 20: Loss 0.6388\n","Run 3, Epoch 30: Loss 0.5668\n","Run 3, Epoch 40: Loss 0.5277\n","Run 3, Epoch 50: Loss 0.4917\n","Run 3, Epoch 60: Loss 0.4671\n","Run 3, Epoch 70: Loss 0.4461\n","Run 3, Epoch 80: Loss 0.4259\n","Run 3, Epoch 90: Loss 0.4111\n","Run 3, Epoch 100: Loss 0.3918\n","Run 3, Epoch 110: Loss 0.3811\n","Run 3, Epoch 120: Loss 0.3680\n","Run 3, Epoch 130: Loss 0.3534\n","Run 3, Epoch 140: Loss 0.3426\n","Run 3, Epoch 150: Loss 0.3233\n","Run 3, Epoch 160: Loss 0.3050\n","Run 3, Epoch 170: Loss 0.3045\n","Run 3, Epoch 180: Loss 0.2981\n","Run 3, Epoch 190: Loss 0.2942\n","Run 3: Model Test Accuracy: 0.8789\n","Run 4, Epoch 0: Loss 1.5527\n","Run 4, Epoch 10: Loss 0.6999\n","Run 4, Epoch 20: Loss 0.5039\n","Run 4, Epoch 30: Loss 0.4217\n","Run 4, Epoch 40: Loss 0.3683\n","Run 4, Epoch 50: Loss 0.3377\n","Run 4, Epoch 60: Loss 0.3157\n","Run 4, Epoch 70: Loss 0.2930\n","Run 4, Epoch 80: Loss 0.2826\n","Run 4, Epoch 90: Loss 0.2685\n","Run 4, Epoch 100: Loss 0.2565\n","Run 4, Epoch 110: Loss 0.2449\n","Run 4, Epoch 120: Loss 0.2340\n","Run 4, Epoch 130: Loss 0.2307\n","Run 4, Epoch 140: Loss 0.2259\n","Run 4, Epoch 150: Loss 0.2213\n","Run 4, Epoch 160: Loss 0.2135\n","Run 4, Epoch 170: Loss 0.2062\n","Run 4, Epoch 180: Loss 0.1988\n","Run 4, Epoch 190: Loss 0.1905\n","Run 4: Model Test Accuracy: 0.8829\n","Run 5, Epoch 0: Loss 1.6236\n","Run 5, Epoch 10: Loss 0.8790\n","Run 5, Epoch 20: Loss 0.6185\n","Run 5, Epoch 30: Loss 0.4970\n","Run 5, Epoch 40: Loss 0.4431\n","Run 5, Epoch 50: Loss 0.4049\n","Run 5, Epoch 60: Loss 0.3921\n","Run 5, Epoch 70: Loss 0.3673\n","Run 5, Epoch 80: Loss 0.3532\n","Run 5, Epoch 90: Loss 0.3382\n","Run 5, Epoch 100: Loss 0.3300\n","Run 5, Epoch 110: Loss 0.3246\n","Run 5, Epoch 120: Loss 0.3088\n","Run 5, Epoch 130: Loss 0.3057\n","Run 5, Epoch 140: Loss 0.2968\n","Run 5, Epoch 150: Loss 0.2965\n","Run 5, Epoch 160: Loss 0.2862\n","Run 5, Epoch 170: Loss 0.2748\n","Run 5, Epoch 180: Loss 0.2660\n","Run 5, Epoch 190: Loss 0.2619\n","Run 5: Model Test Accuracy: 0.8781\n","Average Test Accuracy over 5 runs: 0.8821\n"]}],"source":["avg_accuracy_cheb_citeer, loss_cheb_citeseer = run_experiment_semi_supervised(ChebNetModel_semi, torch.optim.Adam,dataset_citeseer2, criterion)\n"],"id":"SLiAA3L1ZEBB"},{"cell_type":"code","source":[],"metadata":{"id":"k-g41INSZE1-"},"id":"k-g41INSZE1-","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pumbed"],"metadata":{"id":"Ok3C_GSXZFIQ"},"id":"Ok3C_GSXZFIQ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeVZJKNdZFIR"},"outputs":[],"source":["dataset_pubmed2 = add_train_val_test_masks_to_dataset(dataset_pubmed)"],"id":"WeVZJKNdZFIR"},{"cell_type":"markdown","metadata":{"id":"BvpbSi10ZFIR"},"source":["## GCN"],"id":"BvpbSi10ZFIR"},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"d0c557e1-b8cd-47fb-f568-3bdf6e686461","id":"4Ve4ZqMQZFIR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Run 1, Epoch 0: Loss 1.0660\n","Run 1, Epoch 10: Loss 0.5257\n","Run 1, Epoch 20: Loss 0.4254\n","Run 1, Epoch 30: Loss 0.3875\n","Run 1, Epoch 40: Loss 0.3563\n","Run 1, Epoch 50: Loss 0.3418\n","Run 1, Epoch 60: Loss 0.3251\n","Run 1, Epoch 70: Loss 0.3126\n","Run 1, Epoch 80: Loss 0.2988\n","Run 1, Epoch 90: Loss 0.2941\n","Run 1, Epoch 100: Loss 0.2819\n","Run 1, Epoch 110: Loss 0.2784\n","Run 1, Epoch 120: Loss 0.2717\n","Run 1, Epoch 130: Loss 0.2658\n","Run 1, Epoch 140: Loss 0.2632\n","Run 1, Epoch 150: Loss 0.2545\n","Run 1, Epoch 160: Loss 0.2492\n","Run 1, Epoch 170: Loss 0.2467\n","Run 1, Epoch 180: Loss 0.2397\n","Run 1, Epoch 190: Loss 0.2363\n","Run 1: Model Test Accuracy: 0.8786\n","Run 2, Epoch 0: Loss 1.1047\n","Run 2, Epoch 10: Loss 0.5239\n","Run 2, Epoch 20: Loss 0.4380\n","Run 2, Epoch 30: Loss 0.4032\n","Run 2, Epoch 40: Loss 0.3695\n","Run 2, Epoch 50: Loss 0.3522\n","Run 2, Epoch 60: Loss 0.3390\n","Run 2, Epoch 70: Loss 0.3224\n","Run 2, Epoch 80: Loss 0.3140\n","Run 2, Epoch 90: Loss 0.3076\n","Run 2, Epoch 100: Loss 0.2971\n","Run 2, Epoch 110: Loss 0.2939\n","Run 2, Epoch 120: Loss 0.2835\n","Run 2, Epoch 130: Loss 0.2810\n","Run 2, Epoch 140: Loss 0.2764\n","Run 2, Epoch 150: Loss 0.2719\n","Run 2, Epoch 160: Loss 0.2683\n","Run 2, Epoch 170: Loss 0.2554\n","Run 2, Epoch 180: Loss 0.2564\n","Run 2, Epoch 190: Loss 0.2577\n","Run 2: Model Test Accuracy: 0.8796\n","Run 3, Epoch 0: Loss 1.0888\n","Run 3, Epoch 10: Loss 0.5129\n","Run 3, Epoch 20: Loss 0.4317\n","Run 3, Epoch 30: Loss 0.3928\n","Run 3, Epoch 40: Loss 0.3631\n","Run 3, Epoch 50: Loss 0.3520\n","Run 3, Epoch 60: Loss 0.3395\n","Run 3, Epoch 70: Loss 0.3252\n","Run 3, Epoch 80: Loss 0.3165\n","Run 3, Epoch 90: Loss 0.3084\n","Run 3, Epoch 100: Loss 0.3002\n","Run 3, Epoch 110: Loss 0.2932\n","Run 3, Epoch 120: Loss 0.2891\n","Run 3, Epoch 130: Loss 0.2824\n","Run 3, Epoch 140: Loss 0.2754\n","Run 3, Epoch 150: Loss 0.2726\n","Run 3, Epoch 160: Loss 0.2737\n","Run 3, Epoch 170: Loss 0.2621\n","Run 3, Epoch 180: Loss 0.2597\n","Run 3, Epoch 190: Loss 0.2546\n","Run 3: Model Test Accuracy: 0.8794\n","Run 4, Epoch 0: Loss 1.1165\n","Run 4, Epoch 10: Loss 0.5261\n","Run 4, Epoch 20: Loss 0.4318\n","Run 4, Epoch 30: Loss 0.3914\n","Run 4, Epoch 40: Loss 0.3683\n","Run 4, Epoch 50: Loss 0.3491\n","Run 4, Epoch 60: Loss 0.3362\n","Run 4, Epoch 70: Loss 0.3215\n","Run 4, Epoch 80: Loss 0.3149\n","Run 4, Epoch 90: Loss 0.3042\n","Run 4, Epoch 100: Loss 0.2959\n","Run 4, Epoch 110: Loss 0.2947\n","Run 4, Epoch 120: Loss 0.2840\n","Run 4, Epoch 130: Loss 0.2818\n","Run 4, Epoch 140: Loss 0.2760\n","Run 4, Epoch 150: Loss 0.2672\n","Run 4, Epoch 160: Loss 0.2715\n","Run 4, Epoch 170: Loss 0.2683\n","Run 4, Epoch 180: Loss 0.2583\n","Run 4, Epoch 190: Loss 0.2563\n","Run 4: Model Test Accuracy: 0.8799\n","Run 5, Epoch 0: Loss 1.1230\n","Run 5, Epoch 10: Loss 0.5359\n","Run 5, Epoch 20: Loss 0.4452\n","Run 5, Epoch 30: Loss 0.3985\n","Run 5, Epoch 40: Loss 0.3794\n","Run 5, Epoch 50: Loss 0.3529\n","Run 5, Epoch 60: Loss 0.3351\n","Run 5, Epoch 70: Loss 0.3233\n","Run 5, Epoch 80: Loss 0.3136\n","Run 5, Epoch 90: Loss 0.3025\n","Run 5, Epoch 100: Loss 0.2995\n","Run 5, Epoch 110: Loss 0.2902\n","Run 5, Epoch 120: Loss 0.2839\n","Run 5, Epoch 130: Loss 0.2798\n","Run 5, Epoch 140: Loss 0.2753\n","Run 5, Epoch 150: Loss 0.2693\n","Run 5, Epoch 160: Loss 0.2636\n","Run 5, Epoch 170: Loss 0.2583\n","Run 5, Epoch 180: Loss 0.2568\n","Run 5, Epoch 190: Loss 0.2552\n","Run 5: Model Test Accuracy: 0.8776\n","Average Test Accuracy over 5 runs: 0.8790\n"]}],"source":["avg_accuracy_gcn_pumbed, loss_gcn_pumbed = run_experiment_semi_supervised(GCNModel_semi, torch.optim.Adam,dataset_pubmed2, criterion)\n"],"id":"4Ve4ZqMQZFIR"},{"cell_type":"markdown","metadata":{"id":"NL4Nv9KpZFIS"},"source":["## GhebNet"],"id":"NL4Nv9KpZFIS"},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"424f26ba-5b7d-4892-8449-e8c360bef168","id":"31tYZiLcZFIS"},"outputs":[{"name":"stdout","output_type":"stream","text":["Run 1, Epoch 0: Loss 1.5637\n","Run 1, Epoch 10: Loss 0.8667\n","Run 1, Epoch 20: Loss 0.7281\n","Run 1, Epoch 30: Loss 0.5681\n","Run 1, Epoch 40: Loss 0.4478\n","Run 1, Epoch 50: Loss 0.3998\n","Run 1, Epoch 60: Loss 0.3723\n","Run 1, Epoch 70: Loss 0.3483\n","Run 1, Epoch 80: Loss 0.3325\n","Run 1, Epoch 90: Loss 0.3185\n","Run 1, Epoch 100: Loss 0.2954\n","Run 1, Epoch 110: Loss 0.2953\n","Run 1, Epoch 120: Loss 0.2827\n","Run 1, Epoch 130: Loss 0.2745\n","Run 1, Epoch 140: Loss 0.2682\n","Run 1, Epoch 150: Loss 0.2612\n","Run 1, Epoch 160: Loss 0.2485\n","Run 1, Epoch 170: Loss 0.2444\n","Run 1, Epoch 180: Loss 0.2378\n","Run 1, Epoch 190: Loss 0.2361\n","Run 1: Model Test Accuracy: 0.8842\n","Run 2, Epoch 0: Loss 1.5137\n","Run 2, Epoch 10: Loss 0.6887\n","Run 2, Epoch 20: Loss 0.5555\n","Run 2, Epoch 30: Loss 0.4772\n","Run 2, Epoch 40: Loss 0.4271\n","Run 2, Epoch 50: Loss 0.4047\n","Run 2, Epoch 60: Loss 0.3870\n","Run 2, Epoch 70: Loss 0.3682\n","Run 2, Epoch 80: Loss 0.3614\n","Run 2, Epoch 90: Loss 0.3422\n","Run 2, Epoch 100: Loss 0.3316\n","Run 2, Epoch 110: Loss 0.3176\n","Run 2, Epoch 120: Loss 0.3097\n","Run 2, Epoch 130: Loss 0.3036\n","Run 2, Epoch 140: Loss 0.2981\n","Run 2, Epoch 150: Loss 0.2942\n","Run 2, Epoch 160: Loss 0.2883\n","Run 2, Epoch 170: Loss 0.2811\n","Run 2, Epoch 180: Loss 0.2728\n","Run 2, Epoch 190: Loss 0.2704\n","Run 2: Model Test Accuracy: 0.8865\n","Run 3, Epoch 0: Loss 1.9000\n","Run 3, Epoch 10: Loss 0.7492\n","Run 3, Epoch 20: Loss 0.6388\n","Run 3, Epoch 30: Loss 0.5668\n","Run 3, Epoch 40: Loss 0.5277\n","Run 3, Epoch 50: Loss 0.4917\n","Run 3, Epoch 60: Loss 0.4671\n","Run 3, Epoch 70: Loss 0.4461\n","Run 3, Epoch 80: Loss 0.4259\n","Run 3, Epoch 90: Loss 0.4111\n","Run 3, Epoch 100: Loss 0.3918\n","Run 3, Epoch 110: Loss 0.3811\n","Run 3, Epoch 120: Loss 0.3680\n","Run 3, Epoch 130: Loss 0.3534\n","Run 3, Epoch 140: Loss 0.3426\n","Run 3, Epoch 150: Loss 0.3233\n","Run 3, Epoch 160: Loss 0.3050\n","Run 3, Epoch 170: Loss 0.3045\n","Run 3, Epoch 180: Loss 0.2981\n","Run 3, Epoch 190: Loss 0.2942\n","Run 3: Model Test Accuracy: 0.8789\n","Run 4, Epoch 0: Loss 1.5527\n","Run 4, Epoch 10: Loss 0.6999\n","Run 4, Epoch 20: Loss 0.5039\n","Run 4, Epoch 30: Loss 0.4217\n","Run 4, Epoch 40: Loss 0.3683\n","Run 4, Epoch 50: Loss 0.3377\n","Run 4, Epoch 60: Loss 0.3157\n","Run 4, Epoch 70: Loss 0.2930\n","Run 4, Epoch 80: Loss 0.2826\n","Run 4, Epoch 90: Loss 0.2685\n","Run 4, Epoch 100: Loss 0.2565\n","Run 4, Epoch 110: Loss 0.2449\n","Run 4, Epoch 120: Loss 0.2340\n","Run 4, Epoch 130: Loss 0.2307\n","Run 4, Epoch 140: Loss 0.2259\n","Run 4, Epoch 150: Loss 0.2213\n","Run 4, Epoch 160: Loss 0.2135\n","Run 4, Epoch 170: Loss 0.2062\n","Run 4, Epoch 180: Loss 0.1988\n","Run 4, Epoch 190: Loss 0.1905\n","Run 4: Model Test Accuracy: 0.8829\n","Run 5, Epoch 0: Loss 1.6236\n","Run 5, Epoch 10: Loss 0.8790\n","Run 5, Epoch 20: Loss 0.6185\n","Run 5, Epoch 30: Loss 0.4970\n","Run 5, Epoch 40: Loss 0.4431\n","Run 5, Epoch 50: Loss 0.4049\n","Run 5, Epoch 60: Loss 0.3921\n","Run 5, Epoch 70: Loss 0.3673\n","Run 5, Epoch 80: Loss 0.3532\n","Run 5, Epoch 90: Loss 0.3382\n","Run 5, Epoch 100: Loss 0.3300\n","Run 5, Epoch 110: Loss 0.3246\n","Run 5, Epoch 120: Loss 0.3088\n","Run 5, Epoch 130: Loss 0.3057\n","Run 5, Epoch 140: Loss 0.2968\n","Run 5, Epoch 150: Loss 0.2965\n","Run 5, Epoch 160: Loss 0.2862\n","Run 5, Epoch 170: Loss 0.2748\n","Run 5, Epoch 180: Loss 0.2660\n","Run 5, Epoch 190: Loss 0.2619\n","Run 5: Model Test Accuracy: 0.8781\n","Average Test Accuracy over 5 runs: 0.8821\n"]}],"source":["avg_accuracy_cheb_pumbed, loss_cheb_pumbed = run_experiment_semi_supervised(ChebNetModel_semi, torch.optim.Adam,dataset_pubmed2, criterion)\n"],"id":"31tYZiLcZFIS"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}